<!DOCTYPE html>
<html>
<head>
	<title>机器学习</title>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700">
	<link rel="stylesheet" href="note.css">

</head>
<body>
	<div class="container">
		<header>
			<h1>燕伤雪的学习笔记</h1>
			<p>在这里，我将分享我在学习过程中所积累的知识和经验。</p>
		</header>
		<div class="nav">
			<a href="index.html">首页</a>
			<div class="nav-item">
				<a href="#about">学习笔记</a>
				<div class="sub-nav">
				  <a href="#team">团队介绍</a>
				  <a href="#Front End">前端</a>
				  <a href="#Backend">后端</a>
				  <a href="#math">数学</a>
				  <a href="#AI">人工智能</a>
				  <a href="#Data Structures and Algorithms">数据结构与算法</a> 
				  <a href="#other ">其他</a>
				</div>
			  </div>
			<a href="#">项目展示</a>
			<a href="#">社交媒体</a>
			<a href="#">联系方式</a>
		</div>
		<section>
		<h2>一、基本概念简介及其分类：</h2>

	<h3>1.1 有监督学习和无监督学习</h3>
	
	<h4>有监督学习：</h4>
	<p>特点是有预测结果（或者说是有标签）。</p>
	<p>例如：</p>
	
	<pre><code>假设我们有一个房屋销售数据集，数据集包括每个房子的大小、卧室数量、位置和售价。我们希望通过房屋的特征来预测房屋的售价。
	
	在这个例子中，房屋的大小、卧室数量和位置是特征（输入变量），售价是目标变量（输出变量）。我们可以使用一个有监督学习的模型，如线性回归模型或者决策树模型来训练模型，从而预测房屋的售价。
	
	例如，如果我们给模型一个房屋的大小为200平方米，卧室数量为3，位置在市中心，模型可以预测它的售价为300万。如果我们有足够的数据来训练模型，它将可以预测出其他房屋的售价，从而帮助我们了解房地产市场的行情。</code></pre>
	
	<p><strong>有监督学习中又分为两大类，分别是回归和分类。</strong></p>
	
	<p><strong>回归</strong>：指通过输入数据，结合机器学习的模型，来获得一个结果（预测值）</p>
	
	<p><strong>分类</strong>：在分类问题中，模型的目标是根据给定的特征来预测每个输入样本所属的类别。</p>
	
	<pre><code>当提到有监督学习中的分类问题时，最常见的例子可能是手写数字识别。在这个问题中，我们的目标是根据输入的手写数字图像，将其分类为数字0到9中的一种。这个问题被广泛应用于数字字符的自动识别，例如邮政编码识别、银行支票处理等领域。
	
	手写数字识别问题中，输入数据是一张图像，输出是一个标签，即这张图像所代表的数字。</code></pre>
	
	<p><strong>回归和分类最大的区别是，回归的预测值是连续的，而分类的预测标签是离散的。</strong></p>
	
	<h4>无监督学习：</h4>
	<p>特点是没有专门输出一个结果（或标签）。</p>
	<p><strong>无监督学习也分为两大类，分别是聚类和降维：</strong></p>
	<p><strong>聚类</strong>：聚类的目标是在不知道任何样本标签或类别的情况下，将样本划分为不同的组，使得每个组内的对象之间的相似度尽可能高，而不同组之间的相似度尽可能低。</p>

<pre><code>一个常见的聚类问题是图像分割（Image Segmentation），即将一张大的图像分割成若干个小的区域，每个区域包含具有相似特征的像素。例如，对于一张自然景观的照片，我们可能希望将其分割成若干个小的区域，每个区域包含相似的颜色、纹理、亮度等特征。</code></pre>

<p><strong>降维</strong>：降维的目的是在保留数据重要信息的同时，尽可能减少特征的数量，从而减少模型训练和推理的计算成本。例如，如果一个数据集包含1000个特征，那么可以通过降维将其转化为只有10个或100个特征，从而提高模型的效率和准确性。另外，降维还可以帮助我们发现数据中的隐藏结构和模式，从而更好地理解数据的本质特征。</p>

<pre><code>假设我们有一些用户数据，其中包括每个用户的年龄、性别、教育水平、收入、工作经验等属性。我们希望使用这些数据来预测每个用户是否会购买某个产品。在这个例子中，我们可以将每个用户表示为一个向量，其中每个属性表示向量中的一个维度。

然而，这些属性之间可能存在高度相关性和冗余性。例如，收入和工作经验可能高度相关，教育水平和工作经验可能也存在某种程度的相关性。这种冗余和相关性会导致数据维度很高，从而使机器学习算法的训练和推理时间变长，降低算法的效率和准确性。</code></pre>

<p><strong>注：</strong></p>
<ol>
	<li>机器学习的应用常常配合爬虫（获取数据）、正则、数据清洗等来使用。</li>
	<li>人工智能相关电影：《模仿游戏》</li>
</ol>

<h3>1.2 回归</h3>

<p>回归问题主要关注确定一个唯一的因变量（需要预测的值）和一个或多个自变量之间的关系。</p>
<h4>1.2.1一元线性回归：y=a*x+b</h4>

<p>只有一个自变量的回归，其中自变量x是影响Y的因素，也称为维度</p>

<p>做机器学习，没有完美解，只有最优解，做机器学习，就是要以最快的速度，找到误差最小的最优解。</p>

<p>例如，在做线性回归时，有坐标为x1,y1;x2,y2;x3,y3等多个点，就分别把x1,y1;x2,y2;x3,y3代入y=a*x+b中，然后把其他点坐标代入得到的回归方程中，对比哪个回归方程的整体的误差最小，则最终就选则该回归方程作为最优解。</p>

<p><img src="https://user-images.githubusercontent.com/68963283/131196415-4ed3190b-d924-4ee3-9a38-21a2ce7f04b8.png" alt=""></p>

<p>最小二乘法：计算整体的误差的大小时，我们通常不是直接把所有点的误差相加再比较，而是通过求误差的平方的平均值</p>

<h4>1.2.2多元线性回归</h4>

<p>本质上就是算法（或者说公式），从一元一次方程变为了多元一次方程组</p>

<p>y =w1* x1 + w2 * x2 + w3 * x3 + ... + wn * xn + w0 * x0    (w0 * x0 就是截距)</p>
</section>
</body>
</html>	