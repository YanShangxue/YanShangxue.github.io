<!DOCTYPE html>
<html>
<head>
	<title>机器学习</title>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700">
	
    <style>
		body {
    font-family: "Open Sans", sans-serif;
    margin: 0;
    padding: 0;
    background-color: #f8f8f8;
}
.container {
    max-width: 1000px;
    margin: 0 auto;
    padding: 20px;
    display: flex;
    flex-wrap: wrap;
}
header {
    background-color: #333;
    width: 1000px;
    color: #fff;
    padding: 20px;
    text-align: center;
    border-radius: 10px 10px 0 0;
}
h1 {
    margin: 0;
    font-size: 36px;
    font-weight: 960;
}
p {
    margin: 10px 0;
    font-size: 18px;
    line-height: 1.5;
}
.nav {
    background-color: #fff;
    padding: 20px;
    text-align: center;
    border-radius: 0 0 10px 10px;
    box-shadow: 0 5px 10px rgba(0, 0, 0, 0.1);
    flex-grow: 1;
    display: flex;
    flex-wrap: wrap;
    justify-content: center;
}
.nav a {
    text-decoration: none;
    color: #333;
    padding: 10px;
    border: 1px solid #ccc;
    margin: 5px;
    font-weight: bold;
    border-radius: 5px;
    transition: all 0.3s ease;
    display: flex
}
.nav a:hover {
    background-color: #333;
    color: #fff;
}
/* 二级导航栏样式 */
.sub-nav {
    display: none;
    background-color: #f1f1f1;
    position: absolute;
    z-index: 1;
}

/* 二级导航栏链接样式 */
.sub-nav a {
    display: inline-block;
    color: black;
    text-align: center;
    padding: 5px 12px;
    text-decoration: none;
}

/* 二级导航栏链接鼠标悬停效果 */
.sub-nav a:hover {
    background-color: #969696;
}

/* 当鼠标悬停在.nav-item上时显示二级导航栏 */
.nav-item:hover .sub-nav {
    display: block;
}
section {
    margin: 20px;
    padding: 20px;
    background-color: #fff;
    border-radius: 10px;
    box-shadow: 0 5px 10px rgba(0, 0, 0, 0.1);
    flex-grow: 1;
    min-width: 300px;
    max-width: 1000px;
    flex-basis: calc(50% - 40px);
}
h2 {
    font-size: 28px;
    font-weight: 1000;
    margin: 0;
    margin-bottom: 20px;
}
h3 {
    font-size: 20px;
    font-weight: 1000;
    margin: 0;
    margin-bottom: 10px;
}
ul {
    margin: 10px 0;
    padding: 0;
    list-style: none;
    font-size: 18px;
    line-height: 1.5;
}
li {
    margin-bottom: 5px;
    padding-left: 20px;
    position: relative;
}
li:before {
    content: "\2022";
    position: absolute;
left: 0;
top: 2px;
color: #333;
font-size: 20px;
}
.project {
margin-bottom: 20px;
}
.project h3 {
font-size: 20px;
margin-bottom: 10px;
}
.project p {
font-size: 18px;
line-height: 1.5;
margin-bottom: 10px;
}
.project a {

color: #333;
font-size: 18px;
margin-bottom: 10px;
transition: all 0.3s ease;
}
.project a:hover {
color: #007bff;
}
.social {
margin: 20px 0;
font-size: 20px;
line-height: 1.5;
display: flex;
flex-wrap: wrap;
justify-content: center;
}
.social a {
display: inline-block;
margin-right: 50px;
color: #e25a5a;
border-radius: 50%;
height: 50px;
min-width: 82px;
text-align: center;
line-height: 50px;
transition: all 0.3s ease;
}
.social a:hover {
background-color: #007bff;
color: #ffffff;
}
.contact ul {
margin: 10px 0;
padding: 0;
list-style: none;
font-size: 18px;
line-height: 1.5;
}
.contact li {
margin-bottom: 10px;
}
.contact li span {
font-weight: 1000;
margin-right: 10px;
display: inline-block;
width: 100px;
}
@media only screen and (max-width: 768px) {
header {
padding: 10px;
}
h1 {
font-size: 24px;
margin-bottom: 10px;
}
p {
font-size: 16px;
line-height: 1.2;
}
nav {
margin-top: 20px;
padding: 5px;
border-radius: 10px;
}
section {
margin: 10px;
padding: 10px;
}
h2 {
font-size: 24px;
margin-bottom: 10px;
}
h3 {
font-size: 18px;
margin-bottom: 5px;
}
ul {
font-size: 16px;
margin: 5px 0;
}
li {
margin-bottom: 3px;
}
li:before {
font-size: 16px;
}
.project h3 {
font-size: 18px;
margin-bottom: 5px;
}
.project p {
font-size: 16px;
line-height: 1.2;
margin-bottom: 5px;
}
.project a {
font-size: 16px;
margin-bottom: 5px;
}
.social {
margin: 10px 0;
padding: 10px;
}
.social a {
width: 40px;
height: 40px;
line-height: 40px;
}
.contact ul {
font-size: 16px;
margin: 5px 0;
}
.contact li span {
width: 80px;
}


}
	</style>
</head>
<body>
	<div class="container">
		<header>
			<h1>燕伤雪的学习笔记</h1>
			<p>在这里，我将分享我在学习过程中所积累的知识和经验。</p>
		</header>
		<div class="nav">
			<a href="index.html">首页</a>
			<div class="nav-item">
				<a href="#about">学习笔记</a>
				<div class="sub-nav">
				  <a href="#team">团队介绍</a>
				  <a href="#Front End">前端</a>
				  <a href="#Backend">后端</a>
				  <a href="#math">数学</a>
				  <a href="#AI">人工智能</a>
				  <a href="#Data Structures and Algorithms">数据结构与算法</a> 
				  <a href="#other ">其他</a>
				</div>
			  </div>
			<a href="#">项目展示</a>
			<a href="#">社交媒体</a>
			<a href="#">联系方式</a>
		</div>
		<section>
		<h2>一、基本概念简介及其分类：</h2>

	<h3>1.1 有监督学习和无监督学习</h3>
	
	<h4>有监督学习：</h4>
	<p>特点是有预测结果（或者说是有标签）。</p>
	<p>例如：</p>
	
	<pre><code>假设我们有一个房屋销售数据集，数据集包括每个房子的大小、卧室数量、位置和售价。我们希望通过房屋的特征来预测房屋的售价。
	
	在这个例子中，房屋的大小、卧室数量和位置是特征（输入变量），售价是目标变量（输出变量）。我们可以使用一个有监督学习的模型，如线性回归模型或者决策树模型来训练模型，从而预测房屋的售价。
	
	例如，如果我们给模型一个房屋的大小为200平方米，卧室数量为3，位置在市中心，模型可以预测它的售价为300万。如果我们有足够的数据来训练模型，它将可以预测出其他房屋的售价，从而帮助我们了解房地产市场的行情。</code></pre>
	
	<p><strong>有监督学习中又分为两大类，分别是回归和分类。</strong></p>
	
	<p><strong>回归</strong>：指通过输入数据，结合机器学习的模型，来获得一个结果（预测值）</p>
	
	<p><strong>分类</strong>：在分类问题中，模型的目标是根据给定的特征来预测每个输入样本所属的类别。</p>
	
	<pre><code>当提到有监督学习中的分类问题时，最常见的例子可能是手写数字识别。在这个问题中，我们的目标是根据输入的手写数字图像，将其分类为数字0到9中的一种。这个问题被广泛应用于数字字符的自动识别，例如邮政编码识别、银行支票处理等领域。
	
	手写数字识别问题中，输入数据是一张图像，输出是一个标签，即这张图像所代表的数字。</code></pre>
	
	<p><strong>回归和分类最大的区别是，回归的预测值是连续的，而分类的预测标签是离散的。</strong></p>
	
	<h4>无监督学习：</h4>
	<p>特点是没有专门输出一个结果（或标签）。</p>
	<p><strong>无监督学习也分为两大类，分别是聚类和降维：</strong></p>
	<p><strong>聚类</strong>：聚类的目标是在不知道任何样本标签或类别的情况下，将样本划分为不同的组，使得每个组内的对象之间的相似度尽可能高，而不同组之间的相似度尽可能低。</p>

<pre><code>一个常见的聚类问题是图像分割（Image Segmentation），即将一张大的图像分割成若干个小的区域，每个区域包含具有相似特征的像素。例如，对于一张自然景观的照片，我们可能希望将其分割成若干个小的区域，每个区域包含相似的颜色、纹理、亮度等特征。</code></pre>

<p><strong>降维</strong>：降维的目的是在保留数据重要信息的同时，尽可能减少特征的数量，从而减少模型训练和推理的计算成本。例如，如果一个数据集包含1000个特征，那么可以通过降维将其转化为只有10个或100个特征，从而提高模型的效率和准确性。另外，降维还可以帮助我们发现数据中的隐藏结构和模式，从而更好地理解数据的本质特征。</p>

<pre><code>假设我们有一些用户数据，其中包括每个用户的年龄、性别、教育水平、收入、工作经验等属性。我们希望使用这些数据来预测每个用户是否会购买某个产品。在这个例子中，我们可以将每个用户表示为一个向量，其中每个属性表示向量中的一个维度。

然而，这些属性之间可能存在高度相关性和冗余性。例如，收入和工作经验可能高度相关，教育水平和工作经验可能也存在某种程度的相关性。这种冗余和相关性会导致数据维度很高，从而使机器学习算法的训练和推理时间变长，降低算法的效率和准确性。</code></pre>

<p><strong>注：</strong></p>
<ol>
	<li>机器学习的应用常常配合爬虫（获取数据）、正则、数据清洗等来使用。</li>
	<li>人工智能相关电影：《模仿游戏》</li>
</ol>

<h3>1.2 回归</h3>

<p>回归问题主要关注确定一个唯一的因变量（需要预测的值）和一个或多个自变量之间的关系。</p>
<h4>1.2.1一元线性回归：y=a*x+b</h4>

<p>只有一个自变量的回归，其中自变量x是影响Y的因素，也称为维度</p>

<p>做机器学习，没有完美解，只有最优解，做机器学习，就是要以最快的速度，找到误差最小的最优解。</p>

<p>例如，在做线性回归时，有坐标为x1,y1;x2,y2;x3,y3等多个点，就分别把x1,y1;x2,y2;x3,y3代入y=a*x+b中，然后把其他点坐标代入得到的回归方程中，对比哪个回归方程的整体的误差最小，则最终就选则该回归方程作为最优解。</p>

<p><img src="https://user-images.githubusercontent.com/68963283/131196415-4ed3190b-d924-4ee3-9a38-21a2ce7f04b8.png" alt=""></p>

<p>最小二乘法：计算整体的误差的大小时，我们通常不是直接把所有点的误差相加再比较，而是通过求误差的平方的平均值</p>

<h4>1.2.2多元线性回归</h4>

<p>本质上就是算法（或者说公式），从一元一次方程变为了多元一次方程组</p>

<p>y =w1* x1 + w2 * x2 + w3 * x3 + ... + wn * xn + w0 * x0    (w0 * x0 就是截距)</p>
</section>
</body>
</html>	